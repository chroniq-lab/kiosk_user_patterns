{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ae2536",
   "metadata": {},
   "source": [
    "## 1. Extract Monthly Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da3ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config import PATH_KIOSK_USER_PATTERNS_FOLDER, PATH_KIOSK_USER_PATTERNS_REPO, PATH_SSD_ADVAN_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b94ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3648"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "execfile(Path(PATH_KIOSK_USER_PATTERNS_REPO, \"functions/safe_parse_json.py\"))\n",
    "\n",
    "cols = [\n",
    "    \"PLACEKEY\", \"LOCATION_NAME\", \"NAICS_CODE\", \"LATITUDE\", \"LONGITUDE\",\n",
    "    \"STREET_ADDRESS\", \"CITY\", \"REGION\", \"DATE_RANGE_START\", \"DATE_RANGE_END\",\n",
    "    \"RAW_VISITOR_COUNTS\", \"RAW_VISIT_COUNTS\", \"VISITOR_HOME_CBGS\"\n",
    "]\n",
    "monthly_patterns_files = list((PATH_SSD_ADVAN_FOLDER / \"Monthly Patterns\" / \"Foot Traffic\").rglob('**/*.gz'))\n",
    "len(monthly_patterns_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f2ac54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>FILE_NAME</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_13_3_27.csv.gz</td>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_13_3_27.csv.gz</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_30.csv.gz</td>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_30.csv.gz</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_39.csv.gz</td>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_39.csv.gz</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_7_25.csv.gz</td>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_7_25.csv.gz</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_2_11.csv.gz</td>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_2_11.csv.gz</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       file_path  \\\n",
       "0  F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_13_3_27.csv.gz   \n",
       "1  F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_30.csv.gz   \n",
       "2  F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_39.csv.gz   \n",
       "3  F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_7_25.csv.gz   \n",
       "4  F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2023\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_2_11.csv.gz   \n",
       "\n",
       "                                                  FILE_NAME  YEAR  \n",
       "0  data_01bd7440-0105-dcc9-0042-fa0702ed2712_13_3_27.csv.gz  2023  \n",
       "1  data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_30.csv.gz  2023  \n",
       "2  data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_1_39.csv.gz  2023  \n",
       "3  data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_7_25.csv.gz  2023  \n",
       "4  data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_2_11.csv.gz  2023  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Extract year from file path using regex (assuming year is a 4-digit number in the path)\n",
    "monthly_patterns_files_df = pd.DataFrame({\n",
    "    'file_path': monthly_patterns_files,\n",
    "    'FILE_NAME': [f.name for f in monthly_patterns_files],\n",
    "    'YEAR': [int(re.search(r'(\\d{4})', str(f)).group(1)) if re.search(r'(\\d{4})', str(f)) else None for f in monthly_patterns_files]\n",
    "})\n",
    "\n",
    "pd.options.display.max_colwidth = None  # Show full file paths in the DataFrame\n",
    "monthly_patterns_files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc1225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base = PATH_KIOSK_USER_PATTERNS_FOLDER / \"working/processed/kupdat03_advan research monthly patterns\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684461dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3009 unique files in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE_NAME</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_24.csv.gz</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_20.csv.gz</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_19.csv.gz</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_5.csv.gz</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_27.csv.gz</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  FILE_NAME  YEAR\n",
       "0  data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_24.csv.gz  2019\n",
       "1  data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_20.csv.gz  2019\n",
       "2  data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_19.csv.gz  2019\n",
       "3   data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_5.csv.gz  2019\n",
       "4  data_01bd7440-0105-dcc9-0042-fa0702ed2712_03_1_27.csv.gz  2019"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ds.dataset(output_base, format=\"parquet\", partitioning=[\"YEAR\", \"MONTH\"])\n",
    "\n",
    "# Check if the dataset exists and get unique file names\n",
    "try:\n",
    "    # Use PyArrow to read the metadata\n",
    "    table = dataset.to_table(columns=[\"FILE_NAME\",\"YEAR\"])\n",
    "    # Convert to pandas to get unique values\n",
    "    unique_files = table.to_pandas().drop_duplicates().reset_index(drop=True)\n",
    "    # Extract the year as integer from the \"YEAR\" column (e.g., \"YEAR=2023\" -> 2023)\n",
    "    unique_files['YEAR'] = unique_files['YEAR'].str.extract(r'(\\d{4})').astype(int)\n",
    "    print(f\"Found {len(unique_files['FILE_NAME'])} unique files in the dataset\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing the dataset: {e}\")\n",
    "    # Check if the directory exists\n",
    "    if not output_base.exists():\n",
    "        print(f\"Directory does not exist: {output_base}\")\n",
    "\n",
    "\n",
    "unique_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f2c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = monthly_patterns_files_df.merge(\n",
    "        unique_files, \n",
    "        left_on=['FILE_NAME', 'YEAR'], \n",
    "        right_on=['FILE_NAME', 'YEAR'], \n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    # Keep only rows that don't have a match\n",
    "unprocessed = merged[merged['_merge'] == 'left_only']\n",
    "\n",
    "unprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976dcaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('F:/Advan Research/Monthly Patterns/Foot Traffic/2024/data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_54.csv.gz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed.iloc[0]['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79fdf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2024\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_54.csv.gz\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2020\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_2_30.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2020\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_2_30.csv.gz: 'unicodeescape' codec can't decode bytes in position 4147-4148: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2020\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_2_28.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2020\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_2_28.csv.gz: Extra data: line 1 column 4 (char 3)\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2020\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_4_45.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2020\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_4_45.csv.gz: Extra data: line 1 column 4 (char 3)\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_13_5_49.csv.gz\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_5_44.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_5_44.csv.gz: Compressed file ended before the end-of-stream marker was reached\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_5_29.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_5_29.csv.gz: 'unicodeescape' codec can't decode bytes in position 564-565: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_3_21.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2021\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_3_21.csv.gz: 'unicodeescape' codec can't decode bytes in position 3339-3340: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_36.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_36.csv.gz: 'unicodeescape' codec can't decode bytes in position 4722-4723: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_63_2_37.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_63_2_37.csv.gz: 'unicodeescape' codec can't decode bytes in position 1876-1877: truncated \\xXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_10.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_10.csv.gz: Error -3 while decompressing data: invalid code lengths set\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_18.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_18.csv.gz: 'unicodeescape' codec can't decode bytes in position 8109-8113: truncated \\UXXXXXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_5_31.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_5_31.csv.gz: Compressed file ended before the end-of-stream marker was reached\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_34.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_34.csv.gz: CRC check failed 0xa4975a10 != 0x4509642d\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_5.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_5.csv.gz: 'unicodeescape' codec can't decode bytes in position 4647-4648: malformed \\N character escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_3.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_3.csv.gz: Error -3 while decompressing data: invalid block type\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_27.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_27.csv.gz: Error -3 while decompressing data: invalid block type\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_51.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_51.csv.gz: 'unicodeescape' codec can't decode bytes in position 2353-2354: truncated \\UXXXXXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_22.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_22.csv.gz: 'unicodeescape' codec can't decode bytes in position 5510-5514: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_41.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_41.csv.gz: 'unicodeescape' codec can't decode bytes in position 6309-6310: truncated \\xXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_42.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_42.csv.gz: 'unicodeescape' codec can't decode bytes in position 2475-2476: malformed \\N character escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_8.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_8.csv.gz: 'unicodeescape' codec can't decode bytes in position 1483-1484: malformed \\N character escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_40.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_40.csv.gz: Compressed file ended before the end-of-stream marker was reached\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_13.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_13.csv.gz: 'unicodeescape' codec can't decode bytes in position 2209-2211: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_6.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_2_6.csv.gz: Error -3 while decompressing data: invalid block type\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_36.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_36.csv.gz: 'unicodeescape' codec can't decode bytes in position 8077-8079: truncated \\uXXXX escape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_5.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_5.csv.gz: 'unicodeescape' codec can't decode bytes in position 4429-4430: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_30.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_30.csv.gz: 'unicodeescape' codec can't decode bytes in position 6050-6051: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_35.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_35.csv.gz: 'unicodeescape' codec can't decode bytes in position 7599-7600: truncated \\UXXXXXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_9.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_9.csv.gz: 'unicodeescape' codec can't decode bytes in position 1143-1144: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_5_3.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_5_3.csv.gz: 'unicodeescape' codec can't decode bytes in position 3097-3098: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_44.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_44.csv.gz: Compressed file ended before the end-of-stream marker was reached\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_21.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_21.csv.gz: 'unicodeescape' codec can't decode bytes in position 5192-5193: truncated \\UXXXXXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_41.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_1_41.csv.gz: 'unicodeescape' codec can't decode bytes in position 2502-2503: malformed \\N character escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_10.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_10.csv.gz: 'unicodeescape' codec can't decode bytes in position 2508-2510: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_34.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_34.csv.gz: 'unicodeescape' codec can't decode bytes in position 8016-8025: illegal Unicode character\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_24.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_73_5_24.csv.gz: 'unicodeescape' codec can't decode bytes in position 1445-1447: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_49.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_23_2_49.csv.gz: 'unicodeescape' codec can't decode bytes in position 4460-4461: truncated \\xXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_4_34.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_43_4_34.csv.gz: 'unicodeescape' codec can't decode bytes in position 559-560: malformed \\N character escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_2.csv.gz\n",
      "Error processing file F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_53_0_2.csv.gz: 'unicodeescape' codec can't decode bytes in position 2575-2577: truncated \\uXXXX escape\n",
      "Processing file: F:\\Advan Research\\Monthly Patterns\\Foot Traffic\\2022\\data_01bd7440-0105-dcc9-0042-fa0702ed2712_33_1_11.csv.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     df_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43municode_escape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Filter rows where LOCATION_NAME contains 'walmart'\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     walmart_mask \u001b[38;5;241m=\u001b[39m df_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCATION_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwalmart\u001b[39m\u001b[38;5;124m'\u001b[39m, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:252\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    248\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\n\u001b[0;32m    249\u001b[0m     Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] \u001b[38;5;241m|\u001b[39m MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[0;32m    250\u001b[0m ]:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1140\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m     next_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m     rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:805\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;66;03m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 805\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(line, \u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\gzip.py:314\u001b[0m, in \u001b[0;36mGzipFile.read1\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    313\u001b[0m     size \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread1(size)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\gzip.py:507\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    505\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 507\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_list = []\n",
    "\n",
    "import json\n",
    "\n",
    "for f in unprocessed['file_path']:\n",
    "    # Read the gzip-compressed CSV file\n",
    "    print(f\"Processing file: {f}\")\n",
    "    \n",
    "    try:\n",
    "        df_table = pd.read_csv(f, \n",
    "                              compression='gzip', \n",
    "                              usecols=cols, \n",
    "                              engine='python',\n",
    "                              on_bad_lines='skip',\n",
    "                              encoding= 'unicode_escape')\n",
    "\n",
    "        # Filter rows where LOCATION_NAME contains 'walmart'\n",
    "        walmart_mask = df_table['LOCATION_NAME'].str.contains('walmart', case=False, na=False)\n",
    "        df_walmart = (df_table[walmart_mask]\n",
    "                      .assign(\n",
    "                          DATE_RANGE_START=lambda x: pd.to_datetime(x['DATE_RANGE_START']))\n",
    "                      .assign(YEAR =lambda x: x['DATE_RANGE_START'].dt.year,\n",
    "                              MONTH=lambda x: x['DATE_RANGE_START'].dt.month,\n",
    "                              FILE_NAME=f.name))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Expand VISITOR_HOME_CBGS into long format\n",
    "        df_cbgs = (df_walmart.dropna(subset=['VISITOR_HOME_CBGS']).copy())\n",
    "        \n",
    "        df_cbgs = (df_cbgs\n",
    "                   .assign(VISITOR_HOME_CBGS=df_cbgs['VISITOR_HOME_CBGS'].apply(lambda x: json.loads(x) if isinstance(x, str) else {})\n",
    "        ).assign(VISITOR_HOME_CBGS=df_cbgs['VISITOR_HOME_CBGS'].apply(safe_parse_json)\n",
    "        ).assign(VISITOR_HOME_CBGS=df_cbgs['VISITOR_HOME_CBGS'].apply(lambda x: list(x.items()) if isinstance(x, dict) else None))\n",
    "        )\n",
    "\n",
    "        # Then explode\n",
    "        df_long = df_cbgs.explode('VISITOR_HOME_CBGS')\n",
    "        # df_long = df_long.reset_index(drop=True)\n",
    "\n",
    "        df_long = (df_long\n",
    "            .reset_index(drop=True)\n",
    "            .assign(\n",
    "                HOME_CBG=lambda x: x['VISITOR_HOME_CBGS'].apply(lambda y: y[0] if isinstance(y, tuple) else None),\n",
    "                VISITOR_COUNT=lambda x: x['VISITOR_HOME_CBGS'].apply(lambda y: y[1] if isinstance(y, tuple) else None)\n",
    "            ).drop(columns=['VISITOR_HOME_CBGS'])\n",
    "        )\n",
    "        # Save to Parquet with partitioning by YEAR and MONTH\n",
    "        df_long.to_parquet(\n",
    "            output_base,\n",
    "            index=False,\n",
    "            partition_cols=[\"YEAR\", \"MONTH\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {f}: {e}\")\n",
    "        error_list.append(f)\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98286004",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(error_list).to_csv(PATH_KIOSK_USER_PATTERNS_REPO / \"data/kupdat03_advan research monthly patterns errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walmart.iloc[0]['FILE_NAME']  # Display the file name of the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries to lists of key-value pairs\n",
    "df_cbgs['VISITOR_HOME_CBGS'] = df_cbgs['VISITOR_HOME_CBGS'].apply(\n",
    "    lambda x: list(x.items()) if isinstance(x, dict) else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(output_base, format=\"parquet\")\n",
    "\n",
    "df = next(dataset.to_batches(batch_size=10)).to_pandas()\n",
    "df.head(n = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4df9cc",
   "metadata": {},
   "source": [
    "## 2. Extract Home Panel Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fde541",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_panel_files = list((PATH_SSD_ADVAN_FOLDER / \"Monthly Patterns\" / \"Home Panel Summary\").rglob('**/*.gz'))\n",
    "len(home_panel_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from file path using regex (assuming year is a 4-digit number in the path)\n",
    "home_panel_files_df = pd.DataFrame({\n",
    "    'file_path': home_panel_files,\n",
    "    'FILE_NAME': [f.name for f in home_panel_files]\n",
    "})\n",
    "\n",
    "pd.options.display.max_colwidth = None  # Show full file paths in the DataFrame\n",
    "home_panel_files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1879dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_home_panel = PATH_KIOSK_USER_PATTERNS_FOLDER / \"working/processed/kupdat03_advan research home panel summary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d65c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "\n",
    "\n",
    "for f in home_panel_files_df['file_path']:\n",
    "    # Read the gzip-compressed CSV file\n",
    "    print(f\"Processing file: {f}\")\n",
    "    \n",
    "    try:\n",
    "        df_table = pd.read_csv(f, \n",
    "                              compression='gzip', \n",
    "                              engine='python',\n",
    "                              on_bad_lines='skip')\n",
    "\n",
    "        # Create a dictionary mapping state abbreviations to full names\n",
    "        state_abbrev_to_name = {\n",
    "            'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "            'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "            'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "            'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "            'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "            'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "            'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "            'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "            'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "            'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming',\n",
    "            'DC': 'District of Columbia', 'PR': 'Puerto Rico', 'VI': 'Virgin Islands', 'GU': 'Guam',\n",
    "            'AS': 'American Samoa', 'MP': 'Northern Mariana Islands'\n",
    "        }\n",
    "        \n",
    "        df_usa = (df_table[df_table['ISO_COUNTRY_CODE'] == 'US']\n",
    "              .rename(columns={'MON': 'MONTH'})\n",
    "              .assign(FILE_NAME = lambda x: f.name)\n",
    "              .assign(state_name = lambda x: x['REGION'].map(state_abbrev_to_name)))\n",
    "        \n",
    "\n",
    "        \n",
    "        # Print data summary\n",
    "        print(f\"Found {len(df_usa)} USA records\")\n",
    "        # Save to Parquet with partitioning by YEAR and MONTH\n",
    "        df_usa.to_parquet(\n",
    "            output_base_home_panel,\n",
    "            index=False,\n",
    "            partition_cols=[\"YEAR\", \"MONTH\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {f}: {e}\")\n",
    "        error_list.append(f)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177d644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
